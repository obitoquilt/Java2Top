---
title: 《BAT高频面点》计算机网络高频面试题八股文（必看👍）
category: 
  - Java
  - 计算机网络
tag:
  - Java基础
head:
  - - meta
    - name: keywords
      content: HTTP,TCP,UDP,IP,网络,三次握手,四次挥手
    - name: description
      content: 图解《计算机网络-BAT高频面题》全网质量最高计算机网络常见知识点和面试题总结，希望对你有帮助
---

## 网络体系
### 1、说下计算机网络体系结构

计算机网络体系结构，一般有三种：OSI 七层模型、TCP/IP 四层模型、五层结构。

![三种网络体系结构](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/nice-article/weixin-mianznxjsjwllsewswztwxxssc-11ecdc9c-5a06-4429-bfc4-115793749000.jpg)

而OSI 是一个理论上的网络通信模型，TCP/IP 是实际上的网络通信模型，五层结构就是为了介绍网络原理而折中的网络通信模型。

::: info

重点理解记忆 TCP/IP 四层模型

:::

![image-20230409124229318](https://xiaolongcoder.oss-cn-beijing.aliyuncs.com/imgs/Java2Top/java/k202304091242759.png)

TCP/IP 网络通常是由上到下分成 4 层，分别是**应用层，传输层，网络层和网络接口层**。而网络接口层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message）。统称为数据包。

### 2、浏览器地址栏键入网址 URL 到显示网页的过程？

### 3、域名 DNS 解析过程？

DNS，英文全称是 **domain name system**，域名解析系统，它的作用也很明确，就是域名和 IP 相互映射。

DNS 的解析过程如下图：

假设你要查询 **[www.baidu.com](http://www.baidu.com/)** 的 IP 地址:

- 首先会查找浏览器的缓存,看看是否能找到**[www.baidu.com](http://www.baidu.com/)** 对应的 IP 地址，找到就直接返回；否则进行下一步;
- 查询本机系统 `HOSTS` 文件，找到就直接返回；否则进行下一步;
- 将请求发往给本地 DNS 服务器，如果查找到也直接返回，否则继续进行下一步；

- 本地 DNS 服务器向**根域名服务器**发送请求，根域名服务器返回负责`com`的顶级域名服务器的 IP 地址的列表。
- 本地 DNS 服务器再向其中一个负责`com`的顶级域名服务器发送一个请求，返回负责`baidu.com`的权限域名服务器的 IP 地址列表。
- 本地 DNS 服务器再向其中一个权限域名服务器发送一个请求，返回**[www.baidu.comopen in new window](http://www.baidu.com/)**所对应的 IP 地址

> 客户端——》本地域名服务器（递归查询）
>
> 本地域名服务器——》DNS服务器的交互查询是迭代查询

## HTTP

### 1、说说 HTTP 常用的状态码及其含义？

HTTP 状态码首先应该知道个大概的分类：

- 1XX：信息性状态码
- 2XX：成功状态码
- 3XX：重定向状态码
- 4XX：客户端错误状态码
- 5XX：服务端错误状态码

**记住面试常考的即可：**

![image-20230409134623333](https://xiaolongcoder.oss-cn-beijing.aliyuncs.com/imgs/Java2Top/java/k202304091346430.png)

> **说一下 301 和 302 的区别？**

- 301：永久性移动，请求的资源已被永久移动到新位置。服务器返回此响应时，会返回新的资源地址。
- 302：临时性性移动，服务器从另外的地址响应资源，但是客户端还应该使用这个地址。

### 2、HTTP 有哪些请求方式？哪些是幂等的？Resultful风格方法有哪些？

3、说⼀下 GET 和 POST 的区别？

### 3、说一下 HTTP 的报文结构

HTTP 报文有两种，HTTP 请求报文和 HTTP 响应报文：

- **请求**：请求行（请求方法+ `HTTP` 版本+ `URL` 地址）、请求头（key-value 键值对）、空格、请求体

- **响应**：状态行（状态码+状态值+ `HTTP` 版本）、响应头（key-value 键值对）、空格、响应头

**HTTP 常见请求头**：

- `Connection`: keep-alive（开启长连接）
- `User-Agent`（客户端使用的操作系统和浏览器的名称和版本）
- `Accept`：text/html（浏览器可接受类型）
- `Accept-Language`、`Host` (被请求资源的Internet主机和端口号)

### 4、HTTP 请求的过程与原理？

HTTP 协议定义了浏览器怎么向服务器请求文档，以及服务器怎么把文档传给浏览器。

![HTTP 请求的过程和原理](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/nice-article/weixin-mianznxjsjwllsewswztwxxssc-9a1a42b7-c14a-43d8-b8d8-f1f18c9b923b.jpg)

- 每个服务器都有一个进程，它不断监听 TCP 的端口 80，以便发现是否有浏览器向它发出连接建立请求
- 监听到连接请求，就会建立 TCP 连接
- 浏览器向服务器发出浏览某个页面的请求，服务器接着就返回所请求的页面作为响应
- 最后，释放 TCP 连接

> 详细展开说，即 ”键入网址，到回显网页其中发生了什么？“

### 5、说下 HTTP/1.0，1.1，2.0 的区别？

关键需要记住 **HTTP/1.0** 默认是短连接，可以强制开启，HTTP/1.1 默认长连接，HTTP/2.0 采用**多路复用**。

**HTTP/1.0**

- 默认使用**短连接**，每次请求都需要建立一个 TCP 连接。它可以设置`Connection: keep-alive` 这个字段，强制开启长连接。

**HTTP/1.1**

1. **支持断点续传**，对带宽进行了优化，不用每次只要对象一部分而把整个对象传过来（分块传输）支持长连接。
2. **流水线**（piping管道传输），使得一次TCP连接可以多次HTTP通信，并且可以使得发起一次HTTP请求后不用等响应就可以继续发下一次（虚假并行）。
3. 将客户端的队列传输移到了服务端，服务端需要队列顺序处理请求返回，这样就可能造成队头阻塞，HTTP2.0采用多路复用解决了
4. **引入了更多的状态码**，比如206断点传输返回；100，使得不用每次请求都发body，可以先试探的发一个header，看是否有权限，若有返回100，下一次发带body的请求，没有权限返回401.
5. 引入了更多的缓存策略，如if-match
6. 默认开启**长连接**keep-alive，增加HOST域（一台服务器多个虚拟主机）

**缺点**：

1、没有头部压缩，服务器端按队列顺序处理请求

2、队头阻塞（多路复用）

3、服务器只能被动响应，2.x 引入 `主动推送`

**HTTP/2.0**

- **头部压缩**：（2之前 body 有对应压缩算法，但是 header 没有，header 里面有大量固定字段，如 `Accept cookie` 等，大量请求下，会有很多冗余字段，2引入 `Hpack 压缩算法` 对头部进行压缩）
- **多路复用**：（由于1.0 虽然也引入了流水线 长连接 提高了效率，但是服务端只能按队列顺序处理请求返回，会造成对头阻塞）2.0引入**二进制帧**，**stream流**：一个 `TCP` 连接里面可以有多个 `Stream` 流，请求可以再各自 `Stream` 里面并发执行，`Stream` 里面请求响应消息由一个个帧组成，带有 `stream id`，所以不同 `stream` 里面帧可以乱序发送，接收端可以根据 `streamid` 按序拼接。
- **服务器推送**：比如请求 `html`，会直接把你需要的 `js css img` 传给你 不用自己再去请求一次（可以通过 nginx 配置）

**HTTP/3**

HTTP/3 主要有两大变化，**传输层基于 UDP**、使用**QUIC 保证 UDP 可靠性**。

HTTP/2 存在的一些问题，比如重传等等，都是由于 TCP 本身的特性导致的，所以 HTTP/3 在 QUIC 的基础上进行发展而来，QUIC（Quick UDP Connections）直译为快速 UDP 网络连接，底层使用 UDP 进行数据传输。

**HTTP/3 主要有这些特点**：

- 使用 UDP 作为传输层进行通信
- 在 UDP 的基础上 QUIC 协议保证了 HTTP/3 的安全性，在传输的过程中就完成了 TLS 加密握手
- HTTPS 要建⽴⼀个连接，要花费 6 次交互，先是建⽴三次握⼿，然后是 TLS/1.3 的三次握⼿。QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 **3** 次，减少了交互次数。
- QUIC 有⾃⼰的⼀套机制可以保证传输的可靠性的。当某个流发⽣丢包时，只会阻塞这个流，其他流不会受到影响。

我们拿一张图看一下 HTTP 协议的变迁：

![HTTP 协议变迁](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/nice-article/weixin-mianznxjsjwllsewswztwxxssc-9384b248-3ea3-4437-b343-f8b7e73f9157.jpg)

### 6、 HTTP 与 HTTPS 的区别？  

- `HTTP` 不安全，明文传输，端口 80，地址 `Http://`，运行在 `TCP` 之上。
- `HTTPS` 安全，混合加密传输，端口443，地址 `Https://`，相当于是身披 SSL 的 HTTP，**HTTPS** 运行于 **SSL** 之上，**SSL** 运行于 **TCP** 之上。
- `HTTPS` 比 `HTTP` 更安全，但是由于加密解密更耗资源。
- `HTTPS` 混合加密机制：**内容**传输使用**对称加密**，但**对称加密的密钥**使用服务端的证书进行了**非对称加密**。

### 7、HTTPS 的连接过程?

这道题有几个要点：**公私钥、数字证书、加密、对称加密、非对称加密**。

**HTTPS 主要工作流程：**

- 客户端发起 `HTTPS` 请求，携带 `随机数+支持的加密算法+支持的SSL版本` 等信息致服务端
- 服务端选择 `协议版本，加密算法`，然后和 `证书与随机数 `发给客户端
- 客户端验证CA证书合法性（CA公钥事先已经置于浏览器或操作系统）
- 客户端产生随机数（**预主密匙**）并用 **证书公钥** 加密发给服务端
- 客户端告知服务端**将使用加密通信**，用协商的加密算法与通信密匙（`通信密匙=客户端随机数+服务端随机数+预主密匙`）
- 客服端发送消息给服务端，让其**验证客服端**是不是刚才建立信任的客户端（之前全部发送的内容做个摘要）
- 服务端收到加密后的 **预主密匙** 用 **CA私钥** 解密，再结合它的随机数与客户端随机数生成 **通信密匙**（与客户端算法一致，见上）
- 服务端验证客户端发来验证消息，无误告知客户端使用加密通信，也向客户端发送验证消息
- 客户端验证服务端发来的消息，
- 无误后，之后开始使用 `通信密匙` 加密通信

![https 主要流程](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/nice-article/weixin-mianznxjsjwllsewswztwxxssc-d91b220e-a7e0-4856-af53-697c96591ec7.jpg)

> 服务端有一套数字证书（证书内容有公钥、证书颁发机构、失效日期等）

### 8、 对称加密算法与非对称加密算法？  

**对称加密**：使用同一把密钥进行加密解密，运算速度快，安全性较低

**非对称加密**：使用公钥对传输数据加密，再使用密钥对数据解密，运算速度慢，更耗资源，安全性更高

## TCP

## UDP
## IP
## 网络安全
## 网络实战

### 1、 网络模型  （说说OSI七层模型，TCP/IP四层模型、五层模型、各层协议以及作用）

七层模型：应用层（Http、FTP）、表示层（Telnet）、会话层(DNS)、传输层、网络层、数据链路层、物理层

五层模型：应用层（http、DNS、FTP、SMTP、telnet）、传输层（TCP、UDP）、网络层（IP、ICMP、ARP）、数据链路层(ppp)、物理层

TCP/IP四层模型**：数据链路与物理层合称网络接口层（ppp）**

### 4、 HTTP 请求与响应报文格式？  

请求：请求行（请求方法+http版本+url地址）、请求头（key-value键值对）、空格、请求体

响应：状态行（状态码+状态值+http版本）、响应头（key-value键值对）、空格、响应头

### 5 、HTTP 常见状态码以及请求头？  

200、301（永久重定向）、302（临时重定向）、400（请求报文语法错误）、401（授权失败，需要身份验证）、

404（请求资源找不到）、500（内部服务器错误）、502（网关错误）、504（网关超时，超时得不到响应）

**http请求头**：Connection: keep-alive（开启长连接）、User-Agent（客户端使用的操作系统和浏览器的名称和版本）、Accept：text/html（浏览器可接受类型）、Accept-Language、Host(被请求资源的Internet主机和端口号)

### 6、 长连接与短链接？  

长连接：一次TCP连接，多次Http通信

短连接：一次连接，一次通信

### 7 、cookie与session?  

cookie一般存用户信息（Token），session一般通过服务器记录用户状态（购物车）

cookie工作机制：当浏览器第一次访问服务端，服务端创新cookie，可将用户信息存于其中，然后返回给浏览器，下一次访问服务端携带cookie，可以得到用户信息。

session工作机制：当浏览器第一次访问服务端，会创建session，还会创建一个特殊的cookie，name为JsessionId，value为sessionid，返回cookie给浏览器，之后访问服务端携带cookie，取出sessionid得到session。

### 8、 redis session共享？  

由于分布式环境下，对台服务器，当客户端请求服务器A，创建session，返回携带sessionid的cookie给客户端，下次客户端访问服务器B根据sessionid得不到session，就有问题。可以用redis解决，比如将用户信息存入redis，key为sessionid，返回携带sessionid的cookie给客户端，下次访问携带cookie，取出sessionid从redis取出相关信息。

### 9、 禁止cookie怎么办？  

url后附带sessionid

### 10、httpOnly  ？

标记为httpOnly的cookie不能被js调用，可以防止篡改，窃取信息。

### 11、http1.1新特新(比较http1.0)？  

1. **支持断点续传**，对带宽进行了优化，不用每次只要对象一部分而把整个对象传过来（分块传输）支持长连接。
2. **流水线**（piping管道传输），使得一次TCP连接可以多次HTTP通信，并且可以使得发起一次HTTP请求后不用等响应就可以继续发下一次（虚假并行）。
3. 将客户端的队列传输移到了服务端，服务端需要队列顺序处理请求返回，这样就可能造成队头阻塞，HTTP2.0采用多路复用解决了
4. **引入了更多的状态码**，比如206断点传输返回；100，使得不用每次请求都发body，可以先试探的发一个header，看是否有权限，若有返回100，下一次发带body的请求，没有权限返回401.
5. 引入了更多的缓存策略，如if-match
6. 默认开启**长连接**keep-alive，增加HOST域（一台服务器多个虚拟主机）

缺点：

1、没有头部压缩，服务器端按队列顺序处理请求

2、队头阻塞（多路复用）

3、服务器只能被动响应，2.x引入主动推送

### 12、http1.1与http2.0？  

**头部压缩**（2之前body有对应压缩算法，但是header没有，header里面有大量固定字段，如Accept cookie等，大量请求下，会有很多冗余字段，2引入Hpack压缩算法对头部进行压缩）

**多路复用**（由于1.0 虽然也引入了流水线 长连接 提高了效率，但是服务端只能按队列顺序处理请求返回，会造成对头阻塞）2.0引入**二进制帧**，**stream流**，一个tcp连接里面可以有多个stream流，请求可以再各自strem里面并发执行，stream里面请求响应消息由一个个帧组成，带有strem id，所以不同stream里面帧可以乱序发送，接收端可以根据streamid按序拼接。

**服务器推送** 比如请求html，会直接把你需要的js css img传给你 不用自己再去请求一次（可以通过nginx配置）

### 13、http常见字段  ？

- Request Header

- - Host：访问服务器的域名
  - Accept：客户端支持的数据格式（text/html）
  - **Connection**：TCP连接复用（长连接）keep-alive
  - Accept-Encoding：客户端支持数据压缩格式

- Response Header

- - **Content-type**：响应数据格式（对应Accept）
  - Content-length：响应数据长度
  - Content-Encoding：数据压缩格式（gzip）

### 15、HTTP方法有哪些？哪些是幂等的？Resultful风格方法有哪些？

http方法有哪些：get、post、delete(删除某个资源)、head(只传head，不穿body)、put(创建更新资源)，options(描述目标资源的通信选项，支持什么http策略)、trance（主要用于测试与诊断，回显服务器收到的请求）

幂等：GET，HEAD，OPTIONS，TRACE，PUT和DELETE，但是put delete不安全 post不幂等

 Restfule风格是一种软件架构风格，可以使得，get/post/delete/put等方式对请求的处理方法进行区分

### 14、Get与Post区别？

### Get：GET获取资源，Post传递数据；不安全、回退无害、（参数）浏览记录、主动缓存、长度限制（1024）、幂等性、Url编码、url参数传递、参数ASCII字符

幂等性：同样请求被执行一次与连续执行多次的效果是一样的，服务器状态也一样。



get回退无害 post回退需要重新请求 get请求参数拼在url后 可见  post写在body比get安全，get有历史浏览记录，post无 get有缓存 post无 get参数只有asccil编码 get幂等性 安全（一个或多次请求效果一样，服务器状态不变）get发数据url长度有限制。

### 16、ARP作用？

ip地址到mac地址的转化。

### 17、DDos攻击？  

分布式拒绝服务，发起大量请求，大规模消耗目标网站的资源，使其无法正常服务。

### 18、TCP与UDP区别及场景？（首部格式、大小、场景）  

tcp**可靠传输**，面向**字节流**，拥塞控制，流量控制，一对一

udp不可靠传输，面向报文，没有拥塞控制，流量控制，支持一对一，一对多

tcp首部长度若没有选项字段大小20字节，udp首部长度固定8字节（这也是为何udp没有首部长度字段）

###### 使用场景：

tcp效率要求低，准确性要求高的（文件传输）；udp效率要求高，准备要求相对可以低点（QQ聊天，视频通话）

###### 为何udp快：

不需要建立连接、没有超时重传、对收到数据不需给确认、没有流量控制拥塞控制

###### tcp首部格式：

20字节源端口、目的端口、序列号、确认号、数据偏移、保留字、URG、ACK、FIN、PSH、FIN

###### udp首部格式：

首部8字节，源端口、目的端口、包长度、检验和，再计算检验和时还会添加12字节的伪首部

### 19、UDP怎样实现可靠传输？  

可以将可靠传输服务转移到应用层中实现。

1、应用层中增加seq/ack机制，确保数据发送到对端

2、添加超时重传机制

**（只作参考，我没被问到过，所以之前没写）**

### 20、打开一个网址用到的协议？  

TCP、IP、http、ARP、OSPF(IP数据包在路由器上的路由器选择)、DNS

### 21、DNS解析过程？  



### 22、拥塞控制？  

作用：流量控制是防止接收方来不及接收，拥塞控制是防止发送方数据填满网络，出现网络拥塞

拥塞窗口（cwnd）：发送方维护的一个状态量，会根据网络拥塞情况动态变化

swnd=min(rwnd，cwnd)

- **慢开始**：开始cwnd=1，试探性发送一个报文，若收到确认ACK，cwnd翻倍（2 4 8 16），如此反复，当cwnd>=ssthresh，使用**拥塞避免，之后cwnd线性增长，每次+1.**
- **拥塞避免**：每当收到⼀个 ACK 时，cwnd 增加 1/cwnd，因此相当于拥塞避免是呈线性增长。一直增长就会出现拥塞，出现丢包，促发重传，进入拥塞发生
- **快重传**

- - 接收方收到失序的报文段，也就是出现包丢失，会对该包发起重传请求，若发送方连续收到3个重复请求，报文段丢失，马上快速重传
  - cwnd=cwnd/2，ssthresh=cwnd，进入快速恢复

- **快恢复**：速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 RTO 超时那么强烈。

- - cwnd=ssthresh+3(3个数据包已经收到)
  - 重传丢失数据包
  - 若再收到重复ACK,cwnd+1，
  - 若收到新数据ACK,cwnd设置为第一步ssthresh的值，状态已恢复，进入拥塞避免。

### 23、流量控制？

作用：防止发送方无脑发送数据，但接收方处理不过来，导致触发重传机制，无端浪费网络流量

过程：TCP首部窗口字段，Window，接收方可以通过该字段告知发送方自己还有多少缓冲区可以接收数据，以此控制发送方速率

### 24、浏览器输入URL到页面渲染中间过程？ 

 见目录《散文》下，写了专门一篇

### 25、TCP三次握手？  

开始客户端服务端都处于CLOSE状态，然后服务端主动监听某个端口，处于listen状态

**客户端发送SYN报文**：客户端随机初始化seq=x，并将序列号置于TCP首部序列号字段中，并将SYN标志位置为1，发送SYN报文到服务端，客户端变为SYN_SEND

**服务端发送SYN+ACK报文**：服务端收到客户端的SYN报文，也会随机初始化序列号seq=y，并将序列号置于TCP首部序列号字段，还会将x+1置于确认应答号字段中，然后置SYN=1,ACK=1将报文发给客户端，不包含应用层数据，之后服务端处于SYN_REVD状态

**客户端发送ACK报文：**客户端收到服务端报文，向服务端发送确认的确认，置ACK标志位为1，确认应答号为y+1，然后发给服务端，这次可以携带数据，此后，客户端服务端都处于ESTABLISHED状态。

------

客户端发起连接请求报文段（客：SYBN_SEND）

服务端为该TCP连接分配缓存与变量，给予确认（服：SYN_REVD）

客户端为该TCP连接分配缓存与变量（客：ESTABLISHED）,给予确认的确认（服：ESTABLISHED）

### 26、如何在Linux查看TCP状态？  

netstat -napt

### 27、为什么三次握手？  

**三次握⼿才可以阻⽌历史连接的重复初始化**（主要原因）：由于某些原因当旧的连接比新的连接先到达服务端，服务端回发一个SYN+ACK报文，客户端收到后与自己**上下文比对（序列号**），发现这是历史连接（序列号过期或超时），便会发送**RST报文**到服务端终止这次连接。**如果是历史连接（序列号过期或超时），则第三次握⼿发送的报⽂是 RST 报⽂，以此中⽌历史连接，而两次握手不行**。

**同步双方序列号**：TCP通信双方，需维护序列号来保证可靠传输（数据去重，有序等），客户端发送初始化序列号给服务端，服务端收到也要发一个给客户端，客户端收到也要对服务端回复一个确认，两次握手只能保证一方初始化序列能被接收，不能保证两方都可，不可靠

**数据传输可靠性**：服务端接收客户端数据给出确认，代表服务端有接收数据与发送数据能力，不知道客户端有没有接收数据能力，数据不可靠。

**防止资源浪费**：某个连接请求因网络延迟，延至到下一个请求正常连接释放后到达服务端，服务端给出确认，如果两次握手代表连接建立，但是客户端此时不会理会这个延迟请求了，服务端就一致超时重传，浪费资源。也可能客户端的 SYN 阻塞了，重复发送多次 SYN 报⽂，只有两次握手客户端收到报文不会给出确认，那么服务端不知道客户端收到自己发的报文没，那么服务器在收到请求后就会建⽴多个冗余的⽆效链接，造成不必要的资源浪费

### 28、TCP四次挥手？  

客服端发起连接释放报文，TCP首部FIN字段置为1，发送FIN报文（客：FIN_WAITE1）

服务端接收并回传一个确认报文段,ACK=1（服：CLOSE_WAITE 客：FIN_WAITE2）

服务端处理完发起连接释放报文，置FIN=1，TCP主动关闭（服：LAST_ACK）

客户端收到FIN报文，给予回复ACK报文（客：TIME_WAITE）

服务端收到ACK报文，进入CLOSED状态,服务端完成连接释放

客户端等2MSL后，进入CLOSED状态，客户端完成连接释放



1. 服务器端在发送完FIN后还能收到数据吗？

当收到对方的FIN报文时, 仅仅表示对方不在发送数据了, 但是还能接收数据  不发数据，可以接收数据

### 29、为什么四次挥手？

客户端释放连接，但是此时服务端可能还有数据要处理，先暂且给客户端一个回复确认，等处理完后在释放连接，所以要四次

被动方此时有可能还有相应的数据报文需要发送

### 30、为什么要等2MSL（最长报文连接）才彻底释放连接？为什么要Time_wait状态？  

首先知道**MSL**意思（**最长报文存活时间**）

- 防止最后一个ACK被动关闭方没收到，那么被动关闭方可以超时重传，这样一来一回最长就2MSL
- 防止旧连接数据包到达，经过2MSL足够让旧连接报文过期消失

### 31、Time_wait过多有什么危害？  

内存资源占用、端口资源占用（一个TCP连接至少消耗一个端口），每端口，无法建立新连接。

服务器资源受限：服务器监听一个端口，会把连接丢给线程处理，可以继续监听端口，但是线程池处理不了那么多连接。

### 32、Time_wait状态过多的优化？  

（这其实和下面38是同一个问题）

**什么时候产生**：首先调用close()发起主动关闭的一方，再发送最后一个ACK之后

**为何产生**：确保最后一个ACK到达，保证TCP全双工连接可靠释放；使旧的数据包过期消失。

什么时候会产生大量Time_wait：当**请求量比较大**的时候，**而且所有的请求都是短连接的时候**

**如何避免**：多IP增加随机端口；内核参数调优（服务器设置SO_REUSEADDR套接字选项来通知内核，如果端口忙，但TCP连接位于TIME_WAIT状态时可以重用端口）；使用长连接（Connection：keep-alive）、Linux参数net.ipv4.tcp_tw_reuse 和 tcp_timestamps开启，复⽤处于 TIME_WAIT 的 socket 为新的连接所⽤

### 33、TCP怎样保证可靠传输的？  

校验和、确认应答、序列和、超时重传、流量控制、拥塞控制

### 34、DNS使用什么协议？  

53端口；DNS服务器间进行域传输的时候用TCP 53（域名服务器之间进行数据同步，保证数据一致性，要求可靠）；客户端查询DNS服务器时用 UDP 53，DNS查询超过512字节，TCP标志出现 使用TCP发送。

### 35、半连接队列与全连接队列？  

长连接：一次TCP连接，多次Http通信

短连接：一次连接，一次通信

### 36、SYN攻击？

SYN攻击，就是伪造大量虚假IP发起连接，请求，服务端返回SYN+ACK报文，由于IP虚假不会给服务端确认应答，一直便处于半连接状态置于半连接队列，等队列占满，无法给正常连接服务。

### 37、tcp的粘包问题怎么解决？

#### 粘包产生的原因：

1. **发送的数据**小于**TCP发送缓冲区**的大小。
2. TCP将多次写入缓冲区的数据一次发送出去，将会发送粘包；
3. 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。
4. 要发送的数据大于TCP缓冲区剩余空间的大小，将发生拆包。

**解决方法：**使用带**消息头的协议**，消息头存储消息开始标志及消息长度；**消息定长**，每次发送固定长度消息；设置**消息边界**，界限符分割；更复杂的应用层协议

### 38、Time_wait什么时候·产生？为何产生？怎样避免？  

什么时候产生：首先调用close()发起主动关闭的一方，再发送最后一个ACK之后

为何产生：确保最后一个ACK到达，保证TCP全双工连接可靠释放；使旧的数据包过期消失。

什么时候会产生大量Time_wait：当**请求量比较大**的时候，**而且所有的请求都是短连接的时候**

如何避免：多IP增加随机端口；内核参数调优（服务器设置SO_REUSEADDR套接字选项来通知内核，如果端口忙，但TCP连接位于TIME_WAIT状态时可以重用端口）；使用长连接（Connection：keep-alive）、Linux参数net.ipv4.tcp_tw_reuse 和 tcp_timestamps开启，复⽤处于 TIME_WAIT 的 socket 为新的连接所⽤